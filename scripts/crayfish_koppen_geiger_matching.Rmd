
Get Crayfish data from gbif

```{r setup}
library(rgbif)
library(readxl)
library(sp)
library(rgdal)
library(leaflet)
library(leaflet.extras)
library(raster)
library(ows4R)
library(httr)
library(rgeos)
library(bcmaps)
library(tiff)
library(tidyverse)
check <- function(x){tryCatch(if(class(x) == 'logical') 1 else 1, error=function(e) 0)} 
```

```{r read species list}
White_list <- read_excel("data/raw/White list proposal for aquarium crayfish GBIF 22092020.xlsx", 
                         skip = 1)

White_list_redux <- White_list %>% 
  filter(!grepl("Cambarellus sp", Species),
         !grepl("Cherax sp", Species),
         !is.na(key))

table(White_list_redux$rank)
n_distinct(White_list_redux$key)
```

```{r download data}
get_cred <- function(x){
  library(svDialogs)
  
  cred <- Sys.getenv(x)
  
  if(cred == ""){
    input <- dlgInput(paste0("What is your ", x, "?"))
    cred <- input$res
    Sys.setenv(x = cred)
  }
  return(cred)
}

gbif_user <- get_cred("gbif_user")
gbif_pwd <- get_cred("gbif_pwd")
gbif_email <- get_cred("gbif_email")

taxonKeys_origin <- menu(choices = c("White - List", "All crayfish"), 
                         title = "Which taxonkeys?",
                         graphics = TRUE)

if(taxonKeys_origin == 1){
  keys <- unique(White_list_redux$key)
  keys2 <- subset(keys, !is.na(keys))
  folder <- "./data/raw/crayfish-downloads/white-list/"
  taxonKeys_origin_str <- "white-list"
}

if(taxonKeys_origin == 2){
  keys2 <- c(8022, 4479, 8670)
  folder <- "./data/raw/crayfish-downloads/all/"
  taxonKeys_origin_str <- "all"
}

if(taxonKeys_origin == 0){
  stop("Canceled by userinput")
}

if(!dir.exists(folder)){
  dir.create(folder, recursive = TRUE)
}

filelist <- dir(path = folder,
                pattern = ".zip")

rerun <- menu(choices = c("Yes", "No"), 
              title = "Rerun download?",
              graphics = TRUE)

if(rerun == 1 || length(filelist) == 0){
  taxonkey_set1 <- pred_in("taxonKey", keys2)
  
  set1 <- occ_download(taxonkey_set1, 
                       pred("hasCoordinate", TRUE),
                       user = gbif_user, 
                       pwd = gbif_pwd, 
                       email = gbif_email)
  
  repeat{
    Sys.sleep(time = 5)
    test_set1 <- occ_download_meta(set1)
    if(test_set1$status == "SUCCEEDED"){
      data <- occ_download_get(set1, overwrite = TRUE) %>% 
        occ_download_import()
      break()
    }
    print(test_set1$status)
  }
  
  file.copy(from = paste0(test_set1$key, ".zip"),
            to = paste0(folder, test_set1$key, ".zip"))
  
  file.remove(paste0(test_set1, ".zip"))
}

if(rerun == 2 & length(filelist) > 0){
  filelist_info <- file.info(paste0(folder, filelist))
  filelist_info <- filelist_info %>% 
    filter(ctime == max(ctime, na.rm = TRUE)) 
  
  if(nrow(filelist_info) == 1){
    old_data <- rownames(filelist_info)
  }else{
    warning(paste0("Multiple zip-files are the same age. downloading ", 
                   filelist_info[1]))
    old_data <- rownames(filelist_info[1])
  }
  
  data <- read_tsv(unz(old_data, "occurrence.txt"), 
                   col_types = c(decimalLatitude = col_number(),
                                 decimalLongitude = col_number()))
}
```

```{r subset data}
#Subset Non - species records
data <- data %>% 
  filter(species != "")

introduced_species <- data %>% 
  filter(countryCode == "BE") %>% 
  distinct(acceptedTaxonKey, acceptedScientificName) %>% 
  mutate(introduced = TRUE)

SPECIES <- data %>% 
  filter(taxonRank == "SPECIES") %>% 
  distinct(acceptedTaxonKey, genus, specificEpithet) %>% 
  mutate(ASN_2 = paste(genus, specificEpithet)) %>% 
  rename(TK_2 = acceptedTaxonKey) %>% 
  select(TK_2, ASN_2)

data_redux <- data %>% 
  mutate(acceptedScientificName= paste(genus, specificEpithet)) %>% 
  left_join(SPECIES, by = c("acceptedScientificName" = "ASN_2")) %>% 
  mutate(acceptedTaxonKey = TK_2) %>% 
  filter(!is.na(eventDate), 
         !is.na(decimalLatitude),
         eventDate >= "1950-01-01",
         basisOfRecord %in% c("HUMAN_OBSERVATION",
                              "PRESERVED_SPECIMEN",
                              "UNKNOWN"),
         occurrenceStatus == "PRESENT") %>% 
  dplyr::select(gbifID, eventDate, year, month, day, taxonKey, acceptedTaxonKey, 
                acceptedScientificName, decimalLatitude, decimalLongitude, coordinateUncertaintyInMeters,
                countryCode) %>% 
  left_join(introduced_species) %>% 
  filter(is.na(introduced)) %>% 
  distinct(acceptedTaxonKey, acceptedScientificName, decimalLongitude, decimalLatitude, eventDate) %>% 
  mutate(decimalLongitude = as.numeric(decimalLongitude))

not_introduced <- data_redux %>% 
  distinct(acceptedTaxonKey, acceptedScientificName)

crs_wgs <- CRS("+proj=longlat +datum=WGS84 +no_defs")

coord <- data_redux %>%
  dplyr::select(decimalLongitude, decimalLatitude) #dplyr hiervoor is nodig om de functie select te laten lopen. Werkt anders niet door package raster.
data_sp <- SpatialPointsDataFrame(coord,
                                  data = data_redux,
                                  proj4string = crs_wgs)
```

```{r test spatial, eval=FALSE}
library(rworldmap)
# get map
worldmap <- getMap(resolution = "coarse")

plot(worldmap) 
points(data_sp, col = "red")
```

&service=wfs&version=1.1.0.

```{r get belgian borders}
wfs_regions <- "https://eservices.minfin.fgov.be/arcgis/services/R2C/Regions/MapServer/WFSServer"
regions_client <- WFSClient$new(wfs_regions, 
                                serviceVersion = "2.0.0")
regions_client$getFeatureTypes(pretty = TRUE)

url <- parse_url(wfs_regions)
url$query <- list(service = "wfs",
                  #version = "2.0.0", # optional
                  request = "GetFeature",
                  typename = "regions",
                  srsName = "EPSG:4326"
)
request <- build_url(url)

bel_regions <- readOGR(request) #Lambert2008

bel_regions <- spTransform(bel_regions, crs_wgs)
bel_regions <- fix_geo_problems(bel_regions, tries = 5)
```

```{r test bel_regions, eval=FALSE}
leaflet(bel_regions) %>% 
  addTiles() %>% 
  addPolygons()
```

```{r Species without gbifdata}
no_gbif_data <- anti_join(White_list_redux, 
                          data_redux, by = c("key" = "acceptedTaxonKey"))

write_csv(no_gbif_data, "./data/interim/crayfish_missing_from_gbif.csv")
```

```{r overlay with koppen_geiger shapes}
legend <- read_delim("./data/spatial/koppen-geiger/KG_Beck_Legend.csv", ";")

koppen_geiger_shapes <- dir(path = "./data/spatial/koppen-geiger", 
                            pattern = ".shp")
koppen_geiger_shapes <- subset(koppen_geiger_shapes, 
                               !grepl(pattern = ".xml", 
                                      koppen_geiger_shapes))
koppen_geiger_shapes <- unique(koppen_geiger_shapes)
koppen_geiger_shapes <- gsub(pattern = ".shp", 
                             replacement = "", 
                             koppen_geiger_shapes)

for(f in koppen_geiger_shapes){
  shape <- readOGR(dsn = "./data/spatial/koppen-geiger", 
                   layer = f,
                   stringsAsFactors = FALSE)
  shape <- spTransform(shape, crs_wgs)
  shape <- fix_geo_problems(shape, tries = 5)
  shape@data <- shape@data %>% 
    mutate(GRIDCODE = as.double(gridcode)) %>% 
    left_join(legend)
  
  bel_girdcode_intersect <- raster::intersect(shape,bel_regions)
  bel_gridcode <- bel_girdcode_intersect@data %>% 
    distinct(GRIDCODE, Classification) %>% 
    filter(!is.na(Classification))
  
  data_sp_over <- over(data_sp, shape)
  data_overlay <- bind_cols(data_redux, data_sp_over) 
  data_overlay <- data_overlay %>% 
    group_by(acceptedTaxonKey, acceptedScientificName, GRIDCODE) %>% 
    add_tally(name = "n_climate") %>% 
    ungroup() %>% 
    group_by(acceptedTaxonKey, acceptedScientificName) %>% 
    add_tally(name = "n_totaal") %>% 
    ungroup() %>% 
    mutate(perc_climate = n_climate/n_totaal) %>% 
    distinct(acceptedTaxonKey, acceptedScientificName, .keep_all = TRUE) %>% 
    select(-decimalLatitude, -decimalLongitude, -gridcode, -Id, -eventDate) 
  
  data_overlay_sub <- data_overlay %>% 
    filter(GRIDCODE %in% bel_gridcode$GRIDCODE) %>% 
    filter(n_totaal >= 90,
           perc_climate >= 0.2)
  
  fn <- paste("data_overlay", f, taxonKeys_origin_str, sep="_")
  fn2 <- paste(fn, "allSpecies", sep = "_")
  fn <- paste0("./data/output/", fn, ".csv")
  fn2 <- paste0("./data/interim/", fn2, ".csv")
  
  assign(f, shape)
  assign(paste("data_overlay", f, sep="_"), data_overlay_sub)
  assign(paste("data_overlay", f, "allSpecies", sep="_"), data_overlay)
  
  write_csv(data_overlay_sub, file = fn)
  write_csv(data_overlay, file = fn2)
}
```

```{r overlay_stats, eval=FALSE}
n_distinct(data_overlay_future_10km$acceptedScientificName)
unique(data_overlay_future_10km$Classification)

n_distinct(data_overlay_present_10km$acceptedScientificName)
unique(data_overlay_present_10km$Classification)
```

```{r test koppen_geiger, eval=FALSE}
temp_shape_1 <- get(koppen_geiger_shapes[1])
temp_shape_2 <- get(koppen_geiger_shapes[2])

pal_1 <- colorBin(palette = "RdYlGn", domain = as.numeric(temp_shape_1$GRIDCODE))
pal_2 <- colorBin(palette = "RdYlGn", domain = as.numeric(temp_shape_2$GRIDCODE))

map <- leaflet() %>% 
  addTiles() %>% 
  addPolygons(data = temp_shape_1,
              group = koppen_geiger_shapes[1],
              fillColor = ~pal_1(as.numeric(GRIDCODE)),
              popup = ~GRIDCODE) %>% 
  addPolygons(data = temp_shape_2,
              group = koppen_geiger_shapes[2],
              fillColor = ~pal_2(as.numeric(GRIDCODE)),
              popup = ~GRIDCODE) %>% 
  addLayersControl(overlayGroups = koppen_geiger_shapes)

map2a <- leaflet() %>% 
  addTiles() %>% 
  addPolygons(data = temp_shape_1,
              group = ~GRIDCODE,
              fillColor = ~pal_2(as.numeric(GRIDCODE))) %>% 
  addLayersControl(overlayGroups = temp_shape_1@data$GRIDCODE) %>% 
  hideGroup(temp_shape_1@data$GRIDCODE)

map2b <- leaflet() %>% 
  addTiles() %>% 
  addPolygons(data = temp_shape_2,
              group = ~GRIDCODE,
              fillColor = ~pal_2(as.numeric(GRIDCODE))) %>% 
  addLayersControl(overlayGroups = temp_shape_2@data$GRIDCODE) %>% 
  hideGroup(temp_shape_2@data$GRIDCODE)
```



